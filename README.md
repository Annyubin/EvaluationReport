# 💊 의약품 문서 평가 시스템 (최신)

AI 기반으로 의약품 인허가 문서의 품질을 자동 평가하는 Streamlit 웹 시스템입니다.

---

## 🚀 평가 흐름(최신)

1. **문서 유형 선택**: 사이드바에서 수동 선택 또는 자동 분류
2. **문서 업로드**: HWP/DOCX 파일 업로드 (지원 포맷: .hwp, .docx)
3. **제품 유형 추론**: 문서 내용에서 제품명 자동 추론(또는 수동 선택)
4. **유사도 기반 가이드라인 후보 제시**: 제품명과 유사한 가이드라인 후보 5개 시각화(색상 바+이모지)
5. **사용자 가이드라인 선택**: 후보 중 하나 선택
6. **평가 옵션 설정**: 청크 크기, 피드백 길이 등 세부 옵션 조정
7. **평가 시작**: 버튼 클릭 시 평가 진행(진행률 게이지/상태/예상시간 표시)
8. **결과/피드백/메타데이터 표시**: 점수, 등급, 누락, 상세 피드백, 권장사항, 중요문장, 평가에 사용된 기준/가이드라인/유형 등 메타데이터 표시, 결과 다운로드

---

## 🏗️ 폴더 구조

```
문서 평가기/
├── modules/                  # 평가 시스템 핵심 모듈
│   ├── document_loader.py    # 문서 텍스트 추출/전처리/지원 포맷
│   ├── document_classifier.py# 문서 유형 분류 및 설명
│   ├── template_loader.py    # 평가 기준/가이드라인 로드 및 유사도 매칭
│   ├── attention_evaluator.py# AI 평가(진행률/예상시간/최적화)
│   ├── feedback_formatter.py # 결과 포맷팅/다운로드
│   └── evaluation_selector.py# 제품 유형 추론 및 기준 선택
├── guidelines/
│   ├── document/             # 문서유형별 평가 기준 JSON
│   └── product/              # 제품유형별 평가 기준 JSON
├── app.py                    # Streamlit 웹앱 메인
├── main.py                   # CLI 평가 실행(터미널)
├── requirements.txt          # 의존성
└── ...
```

---

## 🌟 주요 기능

- **문서유형/제품유형별 평가 기준 완전 분리**
- **유사도 기반 가이드라인 후보 자동 제시** (부분/키워드/Levenshtein/의료기기 키워드)
- **병행 평가**: 문서유형 기준 + 제품 가이드라인 기준 동시 적용
- **시각적 유사도 표시**: 색상 바, 이모지(✅, ⚠️, ❌)
- **평가 메타데이터**: 사용된 기준, 선택 가이드라인, 총 기준 수 등 표시
- **상세 피드백/누락 항목/개선 권장사항/중요문장** 자동 생성
- **Streamlit 기반 직관적 UI/UX** (사이드바, 컬럼, 반응형, 확장/축소)
- **진행률 게이지(막대 progress bar) 애니메이션**: 평가 진행 시 실제 진행률에 도달할 때까지 1%씩 부드럽게 차오르는 막대 게이지 효과
- **평가 진행상황/예상 남은 시간/상태 안내**: Streamlit 화면과 터미널 로그에 실시간 표시
- **평가 옵션**: 청크 크기(슬라이더), 피드백 길이(라디오), 모델 선택 등 다양한 옵션 제공
- **코드 최적화**: LLM 호출 재시도, UI 업데이트 최적화, 대용량 문서/기준/청크 처리 안정성 향상
- **JSON 전처리/대용량/NaN/공백/이상문자 자동 정리**
- **Fallback 시스템**: 매칭 실패 시 기본 템플릿 자동 생성
- **확장성**: JSON 파일만 추가하면 새로운 유형/제품 즉시 지원
- **CLI 지원**: main.py로 터미널에서 평가 실행 가능(사용법 예시 포함)
- **다운로드**: 평가 결과를 마크다운/JSON으로 다운로드
- **에러 처리/안정성**: 텍스트 추출/가이드라인 로드/평가 중 오류 발생 시 상세 안내 및 복구

---

## 🛠️ 설치 및 실행

```bash
pip install -r requirements.txt
streamlit run app.py
```

---

## ⚙️ 평가 옵션/설정

- **문서 유형/제품 유형**: 자동 분류/추론 또는 수동 선택
- **청크 크기**: 2000~6000자(슬라이더)
- **피드백 길이**: 간단/보통/상세(라디오)
- **AI 모델**: mistral, llama2, codellama 등 선택 가능
- **평가 시작**: 버튼 클릭 시 평가 진행

---

## 📊 평가 결과/다운로드

- **점수/등급/누락 항목/상세 피드백/권장사항/중요문장** 등 다양한 결과 제공
- **진행률/상태/예상 남은 시간** 실시간 표시
- **마크다운/JSON 다운로드** 버튼 제공

---

## 📈 확장/관리 방법

- **새로운 문서유형/제품유형 추가**: `guidelines/document/`, `guidelines/product/`에 JSON 파일만 추가
- **평가 기준/가이드라인 관리**: JSON 파일 직접 수정 또는 관리자용 UI 확장 가능
- **AI 모델 교체**: requirements.txt, app.py에서 모델명만 변경
- **CLI 평가 실행**: main.py 사용(지원 포맷: .hwp, .docx)

---

## 🧪 테스트

```bash
python test_new_system.py
python test_integration.py
```

---

## ❓ FAQ

- **Q. 새로운 문서/제품 유형을 추가하려면?**
  - A. `guidelines/document/`, `guidelines/product/`에 JSON 파일만 추가하면 자동 인식됩니다.
- **Q. 평가 기준이 없으면?**
  - A. Fallback으로 기본 평가 기준이 자동 적용됩니다.
- **Q. 평가 결과는 어디서 확인?**
  - A. 웹 UI에서 바로 확인, 마크다운/JSON 다운로드 가능
- **Q. 지원 파일 포맷은?**
  - A. .hwp, .docx (추가 포맷은 document_loader.py 참고)
- **Q. 평가 옵션은?**
  - A. 청크 크기, 피드백 길이, AI 모델 등 다양한 옵션을 사이드바에서 설정 가능
- **Q. 에러가 발생하면?**
  - A. 상세 안내 메시지와 함께 복구/재시도/기본 기준 적용 등 자동 처리

---

## 📝 라이선스 및 문의

- **라이선스**: MIT
- **문의**: 개발팀 또는 이슈 등록

---

**최신 개선사항이 모두 반영된 README입니다.** 