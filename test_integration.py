#!/usr/bin/env python3
"""
ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import logging
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# ëª¨ë“ˆ import
from modules.document_loader import DocumentLoader
from modules.document_classifier import DocumentClassifier
from modules.template_loader import TemplateLoader
from modules.attention_evaluator import AttentionEvaluator
from modules.feedback_formatter import FeedbackFormatter
from modules.evaluation_selector import EvaluationSelector

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_module_imports():
    """ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª ëª¨ë“ˆ Import í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # ê° ëª¨ë“ˆ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
        document_loader = DocumentLoader()
        print("âœ… DocumentLoader ì´ˆê¸°í™” ì„±ê³µ")
        
        document_classifier = DocumentClassifier()
        print("âœ… DocumentClassifier ì´ˆê¸°í™” ì„±ê³µ")
        
        template_loader = TemplateLoader()
        print("âœ… TemplateLoader ì´ˆê¸°í™” ì„±ê³µ")
        
        attention_evaluator = AttentionEvaluator()
        print("âœ… AttentionEvaluator ì´ˆê¸°í™” ì„±ê³µ")
        
        feedback_formatter = FeedbackFormatter()
        print("âœ… FeedbackFormatter ì´ˆê¸°í™” ì„±ê³µ")
        
        evaluation_selector = EvaluationSelector()
        print("âœ… EvaluationSelector ì´ˆê¸°í™” ì„±ê³µ")
        
        print("\nğŸ‰ ëª¨ë“  ëª¨ë“ˆ ì´ˆê¸°í™” ì„±ê³µ!")
        return True
        
    except Exception as e:
        print(f"âŒ ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        logger.error(f"ëª¨ë“ˆ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def test_evaluation_flow():
    """í‰ê°€ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ”„ í‰ê°€ í”Œë¡œìš° í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        document_loader = DocumentLoader()
        document_classifier = DocumentClassifier()
        template_loader = TemplateLoader()
        attention_evaluator = AttentionEvaluator()
        feedback_formatter = FeedbackFormatter()
        evaluation_selector = EvaluationSelector()
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_text = """
        í¡ìˆ˜ì„± ë§ˆê·¸ë„¤ìŠ˜ í•©ê¸ˆì„ ì´ìš©í•œ ì •í˜•ìš© ì´ì‹ì˜ë£Œê¸°ê¸° í—ˆê°€ì‹¬ì‚¬ ê°€ì´ë“œë¼ì¸
        
        ë³¸ ë¬¸ì„œëŠ” í¡ìˆ˜ì„± ë§ˆê·¸ë„¤ìŠ˜ í•©ê¸ˆì„ ì´ìš©í•œ ì •í˜•ìš© ì´ì‹ì˜ë£Œê¸°ê¸°ì˜ í—ˆê°€ì‹¬ì‚¬ì— 
        í•„ìš”í•œ ê¸°ìˆ ë¬¸ì„œ ì‘ì„± ë°©ë²•ê³¼ í‰ê°€ ê¸°ì¤€ì„ ì œì‹œí•©ë‹ˆë‹¤.
        
        ì œí’ˆì˜ ì•ˆì „ì„±ê³¼ íš¨ê³¼ì„±ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ì„ìƒì‹œí—˜ ë°ì´í„°ì™€ ë¹„ì„ìƒ ë°ì´í„°ê°€ 
        í¬í•¨ë˜ì–´ì•¼ í•˜ë©°, ìœ„í—˜ê´€ë¦¬ê³„íšì„œì™€ í•¨ê»˜ ì œì¶œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
        """
        
        print("ğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ")
        
        # 1. ì œí’ˆ ìœ í˜• ì¶”ë¡ 
        print("\n1ï¸âƒ£ ì œí’ˆ ìœ í˜• ì¶”ë¡ ")
        criteria_data, product_type, confidence = evaluation_selector.select_evaluation_criteria(test_text, template_loader)
        print(f"   ì¶”ë¡  ê²°ê³¼: {product_type} (ì‹ ë¢°ë„: {confidence:.2f})")
        
        if criteria_data:
            print("   âœ… í‰ê°€ ê¸°ì¤€ ë¡œë”© ì„±ê³µ")
        else:
            print("   âš ï¸ í‰ê°€ ê¸°ì¤€ ë¡œë”© ì‹¤íŒ¨")
        
        # 2. ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜
        print("\n2ï¸âƒ£ ë¬¸ì„œ ìœ í˜• ë¶„ë¥˜")
        classification_result = document_classifier.classify_document(test_text)
        document_type = classification_result["document_type"]
        print(f"   ë¶„ë¥˜ ê²°ê³¼: {document_type} (ì‹ ë¢°ë„: {classification_result['confidence']})")
        
        # 3. í‰ê°€ ê¸°ì¤€ ì¤€ë¹„
        print("\n3ï¸âƒ£ í‰ê°€ ê¸°ì¤€ ì¤€ë¹„")
        if criteria_data:
            # ìƒˆë¡œìš´ í˜•ì‹ì„ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            if isinstance(criteria_data.get("evaluation_criteria"), list):
                evaluation_criteria = {}
                for criteria in criteria_data["evaluation_criteria"]:
                    evaluation_criteria[criteria["name"]] = {
                        "weight": criteria["weight"],
                        "description": criteria["description"],
                        "sub_criteria": [sub["name"] for sub in criteria["sub_criteria"]]
                    }
            else:
                evaluation_criteria = criteria_data.get("evaluation_criteria", criteria_data)
        else:
            # ê¸°ë³¸ í‰ê°€ ê¸°ì¤€ ì‚¬ìš©
            evaluation_criteria = {
                "ì •í™•ì„±": {
                    "weight": 0.3,
                    "description": "ì •í™•í•œ ì •ë³´ê°€ ê¸°ìˆ ë˜ì—ˆëŠ”ê°€",
                    "sub_criteria": ["ì •ë³´ì˜ ì •í™•ì„±", "ë°ì´í„°ì˜ ì‹ ë¢°ì„±"]
                },
                "í‘œí˜„ë ¥": {
                    "weight": 0.2,
                    "description": "ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ í‘œí˜„ì¸ê°€",
                    "sub_criteria": ["ë¬¸ì¥ì˜ ëª…í™•ì„±", "ì´í•´ì˜ ìš©ì´ì„±"]
                }
            }
        
        print(f"   í‰ê°€ ê¸°ì¤€ ìˆ˜: {len(evaluation_criteria)}")
        
        # 4. ë¬¸ì„œ í‰ê°€
        print("\n4ï¸âƒ£ ë¬¸ì„œ í‰ê°€")
        evaluation_result = attention_evaluator.evaluate_document(
            test_text, evaluation_criteria, document_type
        )
        
        if evaluation_result:
            print("   âœ… í‰ê°€ ì™„ë£Œ")
            print(f"   ì´ì : {evaluation_result.get('ì´ì ', 'N/A')}")
        else:
            print("   âŒ í‰ê°€ ì‹¤íŒ¨")
        
        print("\nğŸ‰ í‰ê°€ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ í‰ê°€ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.error(f"í‰ê°€ í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_file_operations():
    """íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ“ íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # ì§€ì› íŒŒì¼ í˜•ì‹ í™•ì¸
        document_loader = DocumentLoader()
        supported_formats = document_loader.get_supported_formats()
        print(f"ì§€ì› íŒŒì¼ í˜•ì‹: {supported_formats}")
        
        # ìƒˆë¡œìš´ ê°€ì´ë“œë¼ì¸ êµ¬ì¡° í™•ì¸
        guidelines_dir = Path("guidelines")
        if guidelines_dir.exists():
            print("âœ… guidelines ë””ë ‰í† ë¦¬ ì¡´ì¬")
            
            # document í´ë” í™•ì¸
            document_dir = guidelines_dir / "document"
            if document_dir.exists():
                doc_files = list(document_dir.glob("*.json"))
                print(f"ë¬¸ì„œ ìœ í˜•ë³„ ê°€ì´ë“œë¼ì¸ íŒŒì¼ ìˆ˜: {len(doc_files)}")
                for file_path in doc_files:
                    print(f"   ğŸ“„ {file_path.name}")
            
            # product í´ë” í™•ì¸
            product_dir = guidelines_dir / "product"
            if product_dir.exists():
                prod_files = list(product_dir.glob("*.json"))
                print(f"ì œí’ˆë³„ ê°€ì´ë“œë¼ì¸ íŒŒì¼ ìˆ˜: {len(prod_files)}")
                for file_path in prod_files[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                    print(f"   ğŸ“„ {file_path.name}")
                if len(prod_files) > 5:
                    print(f"   ... ì™¸ {len(prod_files) - 5}ê°œ íŒŒì¼")
        else:
            print("âš ï¸ guidelines ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        print("\nğŸ‰ íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.error(f"íŒŒì¼ ì‘ì—… í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_available_options():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í…ŒìŠ¤íŠ¸"""
    print("\n\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    try:
        # ë¬¸ì„œ ìœ í˜• ëª©ë¡
        template_loader = TemplateLoader()
        document_types = template_loader.get_available_types()
        print(f"ë¬¸ì„œ ìœ í˜• ìˆ˜: {len(document_types)}")
        for doc_type in document_types:
            print(f"   ğŸ“„ {doc_type}")
        
        # ì œí’ˆ ìœ í˜• ëª©ë¡
        evaluation_selector = EvaluationSelector()
        product_types = evaluation_selector.get_available_products()
        print(f"\nì œí’ˆ ìœ í˜• ìˆ˜: {len(product_types)}")
        for product_type in product_types:
            print(f"   ğŸ·ï¸ {product_type}")
        
        # ì§€ì› íŒŒì¼ í˜•ì‹
        document_loader = DocumentLoader()
        supported_formats = document_loader.get_supported_formats()
        print(f"\nì§€ì› íŒŒì¼ í˜•ì‹: {supported_formats}")
        
        print("\nğŸ‰ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.error(f"ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ì „ì²´ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    test_results = []
    
    # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_results.append(test_module_imports())
    test_results.append(test_evaluation_flow())
    test_results.append(test_file_operations())
    test_results.append(test_available_options())
    
    # ê²°ê³¼ ìš”ì•½
    print("\n\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    
    passed = sum(test_results)
    total = len(test_results)
    
    print(f"í†µê³¼: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("âœ… ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("âŒ ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 